{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Antonomaz/Corpus.git 2> nul || cd Corpus && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2839 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7370b955c23a41cc9b347e5292fda980"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFeatureNotFound\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 40\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m tqdm(files):\n\u001B[1;32m     39\u001B[0m \t\u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 40\u001B[0m \t\tsoup \u001B[38;5;241m=\u001B[39m \u001B[43mBeautifulSoup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mxml\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \thead \u001B[38;5;241m=\u001B[39m soup\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mteiHeader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     45\u001B[0m \tbody \u001B[38;5;241m=\u001B[39m soup\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/bs4/__init__.py:248\u001B[0m, in \u001B[0;36mBeautifulSoup.__init__\u001B[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     builder_class \u001B[38;5;241m=\u001B[39m builder_registry\u001B[38;5;241m.\u001B[39mlookup(\u001B[38;5;241m*\u001B[39mfeatures)\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m builder_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 248\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m FeatureNotFound(\n\u001B[1;32m    249\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a tree builder with the features you \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    250\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequested: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m. Do you need to install a parser library?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    251\u001B[0m             \u001B[38;5;241m%\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(features))\n\u001B[1;32m    253\u001B[0m \u001B[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;66;03m# with the remaining **kwargs.\u001B[39;00m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m builder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mFeatureNotFound\u001B[0m: Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "import json\n",
    "from numpy import mean, std, amax, amin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def is_LGERM(word):\n",
    "\treturn word in mots_LGERM\n",
    "\n",
    "def is_LGERM_phrase(phrase):\n",
    "\treturn sum(is_LGERM(word) for word in phrase.split())\n",
    "\n",
    "def ttr_line(phrase):\n",
    "\treturn mean([is_LGERM(word) for word in phrase.split()])\n",
    "\n",
    "def ttr_page(page):\n",
    "\treturn [ttr_line(line) for line in page]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"LGERM.json\", encoding=\"utf-8\") as f:\n",
    "    LGERM = json.load(f)\n",
    "mots_LGERM = set(LGERM)\n",
    "\n",
    "path = \"Corpus/Mazarinades/[1-9]*/*.xml\"\n",
    "\n",
    "files = glob(path)\n",
    "\n",
    "print(len(files))\n",
    "\n",
    "\n",
    "lstttrpages = []\n",
    "for file in tqdm(files):\n",
    "\twith open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "\t\tsoup = BeautifulSoup(f, features=\"xml\")\n",
    "\n",
    "\thead = soup.find(\"teiHeader\")\n",
    "\n",
    "\n",
    "\tbody = soup.find(\"text\").find(\"body\").find(\"p\")\n",
    "\n",
    "\t# Create a list of lines, each line is separed by a <lb/> tag or inside a <l> tag\n",
    "\n",
    "\tlines = []\n",
    "\n",
    "\tfor child in body.children:\n",
    "\t\tif child.name == \"l\":\n",
    "\t\t\tlines.append(child.text)\n",
    "\t\telif child.name == \"pb\":\n",
    "\t\t\tlines.append(f\"$$$Page_{child['n']}$$$\")\n",
    "\n",
    "\n",
    "\tlines = [line.strip() for line in lines if line not in [\"\\n\", \"\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tpages = []\n",
    "\tfor line in lines:\n",
    "\n",
    "\t\tif line.__contains__(\"FIN\"):\n",
    "\t\t\tcontinue\n",
    "\t\tif line.startswith(\"$$$Page_\"):\n",
    "\t\t\tif len(pages) > 0 and not pages[-1]:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tpages.append([])\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tpages[-1].append(line)\n",
    "\n",
    "\n",
    "\n",
    "\t#lgrempages = [[(len(line.split()), is_LGERM_phrase(line)) for line in page] for page in pages]\n",
    "\n",
    "\n",
    "\tttrpages = [ttr_page(page) for page in pages]\n",
    "\n",
    "\tlstttrpages.append(ttrpages)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstttrpages[2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstttrpages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# construct some data like what you have:\n",
    "#x = np.array(lstttrpages)\n",
    "\n",
    "min = lambda x: np.min(x, axis=0)\n",
    "max = lambda x: np.max(x, axis=0)\n",
    "mean = lambda x: np.mean(x, axis=0)\n",
    "std = lambda x: np.std(x, axis=0)\n",
    "\n",
    "x = np.array((min(e), max(e), mean(e), std(e)) for e in lstttrpages)\n",
    "\n",
    "# create stacked errorbars:\n",
    "plt.errorbar(np.arange(2), means, std, fmt='ok', lw=3)\n",
    "plt.errorbar(np.arange(2), means, [means - mins, maxes - means],\n",
    "             fmt='.k', ecolor='gray', lw=1)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstttrpages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a bar plot showing the statistics for each page\n",
    "n_pages = len(lstttrpages[0])\n",
    "mean_ttr = np.zeros(n_pages)\n",
    "std_ttr = np.zeros(n_pages)\n",
    "min_ttr = np.zeros(n_pages)\n",
    "max_ttr = np.zeros(n_pages)\n",
    "\n",
    "for i in range(n_pages):\n",
    "    page_ttr = [lstttrpages[j][i] for j in range(len(lstttrpages))]\n",
    "    mean_ttr[i] = np.mean(page_ttr)\n",
    "    std_ttr[i] = np.std(page_ttr)\n",
    "    min_ttr[i] = np.min(page_ttr)\n",
    "    max_ttr[i] = np.max(page_ttr)\n",
    "\n",
    "page_numbers = np.arange(1, n_pages+1)\n",
    "width = 0.2\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(page_numbers - width, mean_ttr, width, label='Mean')\n",
    "ax.bar(page_numbers, std_ttr, width, label='Std Dev')\n",
    "ax.bar(page_numbers + width, max_ttr, width, label='Max')\n",
    "ax.bar(page_numbers + 2*width, min_ttr, width, label='Min')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Page Number')\n",
    "ax.set_ylabel('TTR')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(x.tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ttrpages)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
